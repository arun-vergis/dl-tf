{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning \n",
    "\n",
    "Deep learning is a specific subfield of machine learning that learns to transform input data into increasingly\n",
    "meaningful representations in successive layers, in order to successfully perform a task. \n",
    "\n",
    "These layered representations are learned via models called neural\n",
    "networks\n",
    "\n",
    "How Deep Learning Works:\n",
    "\n",
    "![](./im/how_dl_works.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow\n",
    "\n",
    "[Tensorflow](https://www.tensorflow.org/) is an open source Deep Learning platform developed by Google. \n",
    "\n",
    "Installing Tensorflow:\n",
    "\n",
    "`pip install tensorflow`\n",
    "\n",
    "It is recommended to install Tensorflow in a virtual environment.  \n",
    "\n",
    "You can create a virtual environment by the following command:\n",
    "\n",
    "`python -m venv \\path\\to\\.myenv` \n",
    "\n",
    "\n",
    "where `.myenv` is the name of the environment folder\n",
    "\n",
    "Activating venv on linux:\n",
    "`$ source /path/to/.myenv/bin/activate`\n",
    "\n",
    "Activating on  PowerShell\n",
    "`PS>: path\\to\\.myvenv\\Scripts\\Activate.ps1`\n",
    "\n",
    " On Microsoft Windows, it may be required to enable the Activate.ps1 script by setting the execution policy for the user. You can do this by issuing the following PowerShell command:\n",
    "`PS C:> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser`\n",
    "\n",
    "If you want to switch projects or otherwise leave your virtual environment, simply run:\n",
    "`deactivate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "Keras is a deep learning API for Python, that provides a convenient\n",
    "way to define and train any kind of deep learning model.\n",
    "\n",
    "TensorFlow itself now comes bundled with its own Keras implementation,\n",
    "`tf.keras`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Simple Neural Network with 5 inputs and 2 outputs\n",
    "![ann](./im/ann2.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Neuron\n",
    "![neuron](./im/neuron.jpeg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `Sequential` API in `tf.keras` when our network is composed of a single stack of layers connected sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add a fully connected layer of 4 neurons to our model. We also specify the activation function and input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(4, activation='relu', input_shape=(5,)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add another layer of 2 neurons to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(2)) #no activation, no need to specify input shape-each of the 2 neurons will have 4 inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model’s `summary()` method displays all the model’s layers, including each layer’s\n",
    "name (which is automatically generated unless you set it when creating the layer),  and its number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`None` in output shape means batch size can be anything.\n",
    "\n",
    "Instead of adding the layers one by one as we just did, you can pass a list of layers when creating the Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([tf.keras.layers.Dense(4, input_shape=(5,)),\n",
    "                           tf.keras.layers.Dense(2)])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can fetch a layer by its index, and access its parameters by the `get_weights()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Using the Sequential API, create the network shown below. Use relu activation for layer 1 and layer 2 and sigmoid activation for the output layer. How many parameters will the network have?\n",
    "\n",
    "![ann](./im/annq.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[] your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression using ANN\n",
    "\n",
    "There are two major types of supervised machine learning problems, called classification\n",
    "and regression.\n",
    "In classification, the goal is to predict a class label, which is a choice from a predefined\n",
    "list of possibilities.\n",
    "\n",
    "For regression tasks, the goal is to predict a continuous number\n",
    "\n",
    "Basically, there are two types of regression models.\n",
    "Simple regression, and multiple regression.\n",
    "Simple regression is when one independent variable is used to estimate a dependent variable.\n",
    "It can be either linear, or non-linear. Linearity of regression, is based on the nature of relationship between independent and dependent variables.\n",
    "When more than one independent variable is present, \n",
    "the processes is called multiple regression.\n",
    "Again, depending on the relation between dependent and independent variables,\n",
    "it can be either linear or nonlinear regression.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Polynomial Regression Example\n",
    "\n",
    "We’re going to train a network to model data generated by a quadratic function $y=0.5x^2 +x + 2$.\n",
    "This will result in a model that can take a value, x, and predict its y.\n",
    "\n",
    "For generating training data, start with generating uniformly distributed values from -3 to 3 for x values. Use the quadratic function to generate corresponding y values and add noise to simulate real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values=tf.random.uniform(shape=[100], minval=-3, maxval=3) \n",
    "y_values = 0.5*x_values**2 + x_values + 2 + 0.2* tf.random.normal(x_values.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out the data \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_values, y_values, 'ro')\n",
    "plt.xlabel('x_values')\n",
    "plt.ylabel('y_values')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Keras to create a simple model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(1,))) #\n",
    "model_1.add(tf.keras.layers.Dense(1)) #no activation so that the output is free to range \n",
    "model_1.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a model is created, you must call its `compile()` method to specify the `loss` function\n",
    "and the `optimizer` to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model using a standard optimizer and loss function for regression\n",
    "model_1.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning process will then begin with the `model.fit()` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(x_values, y_values, epochs=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you’ve trained your model, you can use it to make predictions\n",
    "on new data. This is called *inference*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=1, y=?\n",
    "model_1.predict([1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict() method can accept multiple input samples. Let us generate some test data and make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=tf.random.uniform(shape=[100], minval=-3, maxval=3) \n",
    "predictions = model_1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_test, predictions, 'r.', label='predictions')\n",
    "plt.plot(x_test, 0.5*x_test**2+x_test+2, 'b.', label='true values')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to improve our model?\n",
    "More training data? More epochs? More neurons in a layer? More layers? Different activation function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=tf.random.uniform(shape=[1000], minval=-3, maxval=3) #more training data\n",
    "y_train = 0.5*x_train**2 + x_train + 2 + 0.2* tf.random.normal(x_train.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(1,))) \n",
    "model_1.add(tf.keras.layers.Dense(1)) \n",
    "model_1.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation is used to determine if the model is overfitting to training data. Train the model with validation added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(x_train, y_train, epochs=500, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `batch_size` argument specifies how many pieces of training data to feed into\n",
    "the network before measuring the loss and updating the weights and biases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit() method returns a History object containing the training parameters\n",
    "(history.params), the list of epochs it went through (history.epoch), and most\n",
    "importantly a dictionary (history.history) containing the loss and extra metrics it\n",
    "measured at the end of each epoch on the training set and on the validation set (if\n",
    "any). Let us graph the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history_1.history['loss']\n",
    "val_loss = history_1.history['val_loss']\n",
    "plt.plot(loss, label='train loss')\n",
    "plt.plot(val_loss, label='val loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions based on our test dataset\n",
    "predictions = model_1.predict(x_test)\n",
    "\n",
    "# Graph the predictions against the actual values\n",
    "plt.plot(x_test, predictions, 'r.', label='predictions')\n",
    "plt.plot(x_test, 0.5*x_test**2+x_test+2, 'b.', label='actual')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image classification using FCN\n",
    "We will use Fashion MNIST dataset, which is a drop-in replacement of MNIST. It has the exact same\n",
    "format as MNIST (70,000 grayscale images of 28 × 28 pixels each, with 10 classes),\n",
    "but the images represent fashion items rather than handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_train.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With MNIST, when the label is equal to 5, it means that the image represents the\n",
    "handwritten digit 5. Easy. For Fashion MNIST, however, we need the list of class\n",
    "names to know what we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the first image in the dataset and its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0], cmap='gray') \n",
    "plt.axis(\"off\")\n",
    "plt.title(class_names[y_train[0]]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are going to train the\n",
    "neural network using Gradient Descent, we must scale the input features. (this also converts them to floats):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test/ 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the neural network that makes up our model. \n",
    "Our network will use 100 neurons in the hidden layer:\n",
    "\n",
    "![A graph showing the network](./im/dense-multilayer-network-fashionmnist-small.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "tf.keras.layers.Dense(100, activation='relu'),\n",
    "tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation on the output layer is Softmax.\n",
    "\n",
    "Our network layer structure will look like this:\n",
    "\n",
    "![An image showing the network layer structure as it's broken down into layers.](./im/multilayer-network-layers-fashionmnist-small.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call its compile() method to specify the loss function\n",
    "and the optimizer to use. Optionally, you can specify a list of extra metrics to\n",
    "compute during training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=\"adam\",\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function in this case is called sparse categorical cross entropy. \n",
    "[Cross Entropy](https://en.wikipedia.org/wiki/Cross_entropy)\n",
    "\n",
    "The optimizer is `adam` which is an evolution of the\n",
    "stochastic gradient descent (sgd) optimizer that has been shown to be faster and more efficient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the network, we call its fit() method over 10 epochs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob=model.predict(x_test[:3])\n",
    "y_prob.round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can do something new—evaluate the model, using a single line of code.\n",
    "We have a set of 10,000 images and labels for testing, and we can pass them to the\n",
    "trained model to have it predict what it thinks each image is, compare that to its\n",
    "actual label, and sum up the results:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras will use the HDF5 format to save both the model’s architecture (including every\n",
    "layer’s hyperparameters) and the values of all the model parameters for every layer\n",
    "(e.g., connection weights and biases). It also saves the optimizer (including its hyperparameters\n",
    "and any state it may have)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaway\n",
    "\n",
    "Adding more layers to our network will improve accuracy. However, they are not perfect for computer vision tasks. In images, there are some structural patterns that can help us classify an object regardless of it's position in the image, but fully connected networks are not *translation invariant*.\n",
    "\n",
    "Convolutional Neural Networks(CNNs) are more effective for computer vision tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Convolutional Neural Network to recognize fashion images\n",
    "\n",
    "\n",
    "To implement a convolutional layer, we’ll use the `tf.keras.layers.Conv2D` type.\n",
    "This accepts as parameters the number of convolutions to use in the layer, the size of\n",
    "the convolutions, the activation function, etc.\n",
    "For example, here’s a convolutional layer used as the input layer to a neural network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1,\n",
    "padding='same', activation='relu', input_shape=(28, 28, 1)),"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a `Conv2D` layer with 32 filters, each 3 × 3, using a stride of 1 (both\n",
    "horizontally and vertically)\n",
    "\n",
    "`padding` can be `same` or `valid`. \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. When padding=\"same\" and strides=1, the output has the same size as the input.\n",
    "\n",
    "![](./im/conv.gif)\n",
    "\n",
    "Conv2D layers are designed for multicolor images, so we’re specifying the third\n",
    "dimension of input_shape as 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling Layer\n",
    "\n",
    "The second common building block of CNNs is the pooling layer. Their goal is to subsample (i.e., shrink) the input image in order to reduce the computational load, the memory usage, and the number of parameters\n",
    "(thereby limiting the risk of overfitting).\n",
    "\n",
    "A pooling layer has no weights; all it does is aggregate the\n",
    "inputs using an aggregation function such as the max or mean. \n",
    "Figure shows a\n",
    "max pooling layer, which is the most common type of pooling layer. \n",
    "\n",
    "\n",
    "<center><img src=\"./im/max_pooling.png\"/></center>\n",
    "\n",
    "\n",
    "In this example,\n",
    "we use a 2 × 2 pooling kernel, with a stride of 2 and no padding. Only the max input\n",
    "value in each receptive field makes it to the next layer, while the other inputs are\n",
    "dropped.\n",
    "\n",
    "The following code\n",
    "creates a max pooling layer using a 2 × 2 kernel. The strides default to the kernel size,\n",
    "so this layer will use a stride of 2 (both horizontally and vertically). By default, it uses\n",
    "\"valid\" padding (i.e., no padding at all):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool = tf.keras.layers.MaxPool2D(pool_size=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical CNN architecture\n",
    "\n",
    "<center><img src=\"./im/typical_cnn.png\"/></center>\n",
    "\n",
    "A simple CNN to tackle the Fashion MNIST dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Conv2D(64, 3, strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "tf.keras.layers.MaxPooling2D(2, 2),\n",
    "tf.keras.layers.Conv2D(128, 3, strides=1,padding='same', activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Flatten(),\n",
    "tf.keras.layers.Dense(64, activation='relu'),\n",
    "tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "loss='sparse_categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=5, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Learning\n",
    "\n",
    "1. Books\n",
    "\n",
    "![](./im/books.png)\n",
    "\n",
    "2. Tutorials and guide on the tensorflow website\n",
    "https://www.tensorflow.org/overview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a550d3da6a96181bb307f156c458fe427d3660a580c4af88383870135042bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
